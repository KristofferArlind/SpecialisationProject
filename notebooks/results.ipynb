{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67214d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ece8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = \"trr_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6dcd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b76e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../work/ktarlind/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_caps(results_df):\n",
    "    current_results = results_df.copy()\n",
    "    \n",
    "    print(current_results[\"conviction_class\"].value_counts())\n",
    "    \n",
    "    results_na_tested = current_results[current_results[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "    results_row_tested = current_results[~current_results[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "    \n",
    "    print(\"Before cap\")\n",
    "    \n",
    "    print(results_na_tested[\"market_cap_usd\"].min())\n",
    "    print(results_row_tested[\"market_cap_usd\"].min())\n",
    "    \n",
    "    print(results_na_tested[\"market_cap_usd\"].mean())\n",
    "    print(results_row_tested[\"market_cap_usd\"].mean())\n",
    "\n",
    "    print(results_na_tested[\"gvkey\"].nunique())\n",
    "    print(results_row_tested[\"gvkey\"].nunique())\n",
    "\n",
    "    print(results_na_tested[\"gvkey\"].value_counts()[results_na_tested[\"gvkey\"].value_counts() >= 100/7].shape[0])\n",
    "    print(results_row_tested[\"gvkey\"].value_counts()[results_row_tested[\"gvkey\"].value_counts() >= 100/7].shape[0])\n",
    "    \n",
    "    if current_results[\"market_cap_usd\"].min() < 100000:\n",
    "    \n",
    "        results_na_tested = results_na_tested.groupby(\"date\").apply(lambda x: x[x[\"market_cap_usd\"] > x[\"market_cap_usd\"].quantile(min_market_cap_percentile_na)]).reset_index(drop=True)\n",
    "        results_row_tested = results_row_tested.groupby(\"date\").apply(lambda x: x[x[\"market_cap_usd\"] > x[\"market_cap_usd\"].quantile(min_market_cap_percentile_global)]).reset_index(drop=True)\n",
    "\n",
    "        results_na_tested = results_na_tested[results_na_tested[\"volume_usd_5\"] > volume_usd_5_min]\n",
    "        results_row_tested = results_row_tested[results_row_tested[\"volume_usd_5\"] > volume_usd_5_min]\n",
    "\n",
    "        current_results = pd.concat([results_na_tested, results_row_tested])\n",
    "        current_results.sort_values([\"date\", \"gvkey\"], inplace=True)\n",
    "        \n",
    "        print(\"After cap\")\n",
    "\n",
    "        print(results_na_tested[\"market_cap_usd\"].min())\n",
    "        print(results_row_tested[\"market_cap_usd\"].min())\n",
    "        \n",
    "        print(results_na_tested[\"market_cap_usd\"].mean())\n",
    "        print(results_row_tested[\"market_cap_usd\"].mean())\n",
    "\n",
    "        print(results_na_tested[\"gvkey\"].nunique())\n",
    "        print(results_row_tested[\"gvkey\"].nunique())\n",
    "\n",
    "        print(results_na_tested[\"gvkey\"].value_counts()[results_na_tested[\"gvkey\"].value_counts() >= 100/7].shape[0])\n",
    "        print(results_row_tested[\"gvkey\"].value_counts()[results_row_tested[\"gvkey\"].value_counts() >= 100/7].shape[0])\n",
    "        \n",
    "        current_results[\"trr_5_fwd_class\"] = 0\n",
    "        current_results.loc[current_results.groupby(['date'])[\"trr_5_fwd\"].transform(lambda x: x <= x.quantile(0.3333)), \"trr_5_fwd_class\"] = -1\n",
    "        current_results.loc[current_results.groupby(['date'])[\"trr_5_fwd\"].transform(lambda x: x >= x.quantile(0.6666)), \"trr_5_fwd_class\"] = 1\n",
    "\n",
    "        \n",
    "        current_results[\"conviction_class\"] = 0\n",
    "        current_results.loc[current_results.groupby(['date'])[\"conviction\"].transform(lambda x: x <= x.quantile(0.3333)), \"conviction_class\"] = -1\n",
    "        current_results.loc[current_results.groupby(['date'])[\"conviction\"].transform(lambda x: x >= x.quantile(0.6666)), \"conviction_class\"] = 1\n",
    "        print(current_results[\"conviction_class\"].value_counts())\n",
    "\n",
    "    else:\n",
    "        print(\"Results already capped, not capping again\")\n",
    "    return current_results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quantiles(results_df):\n",
    "    results_df = results_df.copy()\n",
    "    results_df['conviction_quantile'] = pd.qcut(results_df['conviction'], quantiles, labels=False)\n",
    "    results_df['top_quantile'] = pd.qcut(results_df['pred_2'], quantiles, labels=False)\n",
    "    results_df['bottom_quantile'] = pd.qcut(results_df['pred_0'], quantiles, labels=False)\n",
    "    return results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_time_period(results_df, first_date, last_date):\n",
    "    current_results = results_df.copy()\n",
    "    current_results = current_results[current_results[\"date\"] > pd.Timestamp(first_date)]\n",
    "    current_results = current_results[current_results[\"date\"] < pd.Timestamp(last_date)]\n",
    "    return current_results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_bear_data(results_df, offset_days = 0):\n",
    "    current_results = results_df.copy()\n",
    "    \n",
    "    current_results[\"date\"] = pd.to_datetime(current_results[\"date\"])\n",
    "    \n",
    "    bear_weeks = pd.read_csv('../bear_weeks.csv', delimiter=';', parse_dates=[1,2], infer_datetime_format=True, dayfirst=True)\n",
    "\n",
    "    date_intervals = []\n",
    "    bear_dates = []\n",
    "    for index, row in bear_weeks.iterrows():\n",
    "        start_date = row['monday_start']\n",
    "        end_date = row['monday_end']\n",
    "        date_intervals.append((pd.Timestamp(start_date) + pd.Timedelta(days=offset_days), pd.Timestamp(end_date) + pd.Timedelta(days=offset_days)))\n",
    "    \n",
    "    for start_date, end_date in date_intervals:\n",
    "        bear_dates.extend(pd.date_range(start_date, end_date, freq='d'))\n",
    "\n",
    "    filtered_results = current_results[current_results[\"date\"].isin(bear_dates)]\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_bull_data(results_df, offset_days = 0):\n",
    "    current_results = results_df.copy()\n",
    "    \n",
    "    current_results[\"date\"] = pd.to_datetime(current_results[\"date\"])\n",
    "    \n",
    "    bull_weeks = pd.read_csv('../bull_weeks.csv', delimiter=';', parse_dates=[1,2], infer_datetime_format=True, dayfirst=True)\n",
    "\n",
    "    date_intervals = []\n",
    "    bull_dates = []\n",
    "    for index, row in bull_weeks.iterrows():\n",
    "        start_date = row['monday_start']\n",
    "        end_date = row['monday_end']\n",
    "        date_intervals.append((pd.Timestamp(start_date) + pd.Timedelta(days=offset_days), pd.Timestamp(end_date) + pd.Timedelta(days=offset_days)))\n",
    "    \n",
    "    for start_date, end_date in date_intervals:\n",
    "        bull_dates.extend(pd.date_range(start_date, end_date, freq='d'))\n",
    "\n",
    "    filtered_results = current_results[current_results[\"date\"].isin(bull_dates)]\n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fcf395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_non_bull_bear_data(results_df, offset_days = 0):\n",
    "    current_results = results_df.copy()\n",
    "    \n",
    "    current_results[\"date\"] = pd.to_datetime(current_results[\"date\"])\n",
    "    \n",
    "    bear_weeks = pd.read_csv('../bear_weeks.csv', delimiter=';', parse_dates=[1,2], infer_datetime_format=True, dayfirst=True)\n",
    "    bull_weeks = pd.read_csv('../bull_weeks.csv', delimiter=';', parse_dates=[1,2], infer_datetime_format=True, dayfirst=True)\n",
    "\n",
    "    bull_bear_dates = []\n",
    "\n",
    "    bull_date_intervals = []\n",
    "    for index, row in bull_weeks.iterrows():\n",
    "        start_date = row['monday_start']\n",
    "        end_date = row['monday_end']\n",
    "        bull_date_intervals.append((pd.Timestamp(start_date) + pd.Timedelta(days=offset_days), pd.Timestamp(end_date) + pd.Timedelta(days=offset_days)))\n",
    "\n",
    "    for start_date, end_date in bull_date_intervals:\n",
    "        bull_bear_dates.extend(pd.date_range(start_date, end_date, freq='d'))\n",
    "\n",
    "\n",
    "    bear_date_intervals = []\n",
    "    for index, row in bear_weeks.iterrows():\n",
    "        start_date = row['monday_start']\n",
    "        end_date = row['monday_end']\n",
    "        bear_date_intervals.append((pd.Timestamp(start_date) + pd.Timedelta(days=offset_days), pd.Timestamp(end_date)  + pd.Timedelta(days=offset_days)))\n",
    "    \n",
    "    for start_date, end_date in bear_date_intervals:\n",
    "        bull_bear_dates.extend(pd.date_range(start_date, end_date, freq='d'))\n",
    "\n",
    "    filtered_results = current_results[~current_results[\"date\"].isin(bull_bear_dates)]\n",
    "    \n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(df, bear_test=False, bull_test=False, rough=True, file_name = None):\n",
    "    current_df = df.copy()\n",
    "    \n",
    "    assert(not (bull_test and bear_test))\n",
    "    \n",
    "    if rough:\n",
    "        if bear_test:\n",
    "            current_df = current_df[current_df[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "        if bull_test:\n",
    "            current_df = current_df[current_df[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "\n",
    "    else:\n",
    "        if bear_test:\n",
    "            current_df = choose_bear_data(current_df)\n",
    "        if bull_test:\n",
    "            current_df = choose_bull_data(current_df)\n",
    "\n",
    "    print(current_df[\"date\"].max())\n",
    "    print(current_df[\"date\"].min())\n",
    "\n",
    "    cm = metrics.confusion_matrix(current_df[\"trr_5_fwd_class\"], current_df[\"conviction_class\"], normalize=\"true\")\n",
    "\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=1.2)\n",
    "    plt_hm = sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\".4f\", cbar=False, linecolor=\"black\", linewidths=1, square=True)  \n",
    "    ax.set_ylabel(\"True values\")\n",
    "    ax.set_xlabel(\"Predicted values\")\n",
    "    ax.xaxis.set_ticklabels(['Under', 'Middle', \"Over\"]);\n",
    "    ax.yaxis.set_ticklabels(['Under', 'Middle', \"Over\"]);\n",
    "            \n",
    "    if file_name is not None:\n",
    "        plt_hm.figure.savefig(f'../figures/{file_name}.pdf', dpi=1000, bbox_inches='tight')\n",
    "            \n",
    "    return plt_hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8527dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bull_bear_mean_deciles(bull_df, bear_df, all_df):\n",
    "    #BULL/BEAR TO BULL/BEAR RETURNS MEAN\n",
    "    plt.rcdefaults()\n",
    "    \n",
    "    current_bull = bull_df.copy()\n",
    "    current_bear = bear_df.copy()\n",
    "    current_all  = all_df.copy()\n",
    "\n",
    "    current_bull[\"trr_5_fwd\"] = (1 + current_bull[\"trr_5_fwd\"]).pow(5) - 1\n",
    "    current_bear[\"trr_5_fwd\"] = (1 + current_bear[\"trr_5_fwd\"]).pow(5) - 1\n",
    "    current_all[\"trr_5_fwd\"] = (1 + current_all[\"trr_5_fwd\"]).pow(5) - 1\n",
    "\n",
    "    current_bull[\"trr_5\"] = (1 + current_bull[\"trr_5\"]).pow(5) - 1\n",
    "    current_bear[\"trr_5\"] = (1 + current_bear[\"trr_5\"]).pow(5) - 1\n",
    "    current_all[\"trr_5\"] = (1 + current_all[\"trr_5\"]).pow(5) - 1\n",
    "\n",
    "    assert(not (na_test and global_test))\n",
    "\n",
    "    assert(not (bull_bear_period_rough and bull_bear_period))\n",
    "\n",
    "\n",
    "    if na_test:\n",
    "        current_bull = current_bull[current_bull[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_bear = current_bear[current_bear[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_all  = current_all[current_all[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "    if global_test:\n",
    "        current_bull = current_bull[~current_bull[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_bear = current_bear[~current_bear[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_all  = current_all[~current_all[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "\n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "    if bull_bear_period_rough:\n",
    "        current_bull_bull = current_bull[current_bull[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "        current_bear_bull = current_bear[current_bear[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "        current_all_bull  = current_all[current_all[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "\n",
    "        current_bull_bear = current_bull[current_bull[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "        current_bear_bear = current_bear[current_bear[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "        current_all_bear  = current_all[current_all[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "\n",
    "        print(current_all_bull[\"date\"].max())\n",
    "        print(current_all_bull[\"date\"].min())\n",
    "\n",
    "        print(current_all_bear[\"date\"].max())\n",
    "        print(current_all_bear[\"date\"].min())\n",
    "\n",
    "\n",
    "    if bull_bear_period:\n",
    "        current_bull_bull = choose_bull_data(current_bull)\n",
    "        current_bear_bull = choose_bull_data(current_bear)\n",
    "        current_all_bull  = choose_bull_data(current_all)\n",
    "\n",
    "        current_bull_bear = choose_bear_data(current_bull)\n",
    "        current_bear_bear = choose_bear_data(current_bear)\n",
    "        current_all_bear  = choose_bear_data(current_all)\n",
    "\n",
    "        print(current_all_bull[\"date\"].max())\n",
    "        print(current_all_bull[\"date\"].min())\n",
    "\n",
    "        print(current_all_bear[\"date\"].max())\n",
    "        print(current_all_bear[\"date\"].min())\n",
    "\n",
    "\n",
    "    current_bull_bull = add_quantiles(current_bull_bull)\n",
    "    current_bear_bull = add_quantiles(current_bear_bull)\n",
    "    current_all_bull = add_quantiles(current_all_bull)\n",
    "\n",
    "    current_bull_bear = add_quantiles(current_bull_bear)\n",
    "    current_bear_bear = add_quantiles(current_bear_bear)\n",
    "    current_all_bear = add_quantiles(current_all_bear)\n",
    "\n",
    "    current_bull = add_quantiles(current_bull)\n",
    "    current_bear = add_quantiles(current_bear)\n",
    "    current_all = add_quantiles(current_all)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "    current_all.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,0])\n",
    "    current_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,1])\n",
    "    current_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,2])\n",
    "\n",
    "    max_y = max(max(current_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               max(current_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               max(current_all.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "    min_y = min(min(current_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               min(current_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               min(current_all.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "    for ax in axs[0,:]:\n",
    "        ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "\n",
    "    axs[0, 0].axhline(current_all[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "    axs[0, 1].axhline(current_all[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "    axs[0, 2].axhline(current_all[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "    axs[0, 0].set_ylabel('All test', fontsize=16)\n",
    "\n",
    "    current_all_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,0])\n",
    "    current_bull_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,1])\n",
    "    current_bear_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,2])\n",
    "\n",
    "    max_y = max(max(current_bull_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               max(current_bear_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               max(current_all_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "    min_y = min(min(current_bull_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               min(current_bear_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               min(current_all_bull.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "    for ax in axs[1,:]:\n",
    "        ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "    axs[1, 0].axhline(current_all_bull[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "    axs[1, 1].axhline(current_all_bull[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "    axs[1, 2].axhline(current_all_bull[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "    axs[1, 0].set_ylabel('Bull test', fontsize=16)\n",
    "\n",
    "\n",
    "    current_all_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,0])\n",
    "    current_bull_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,1])\n",
    "    current_bear_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,2])\n",
    "\n",
    "    max_y = max(max(current_bull_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               max(current_bear_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               max(current_all_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "    min_y = min(min(current_bull_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               min(current_bear_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "               min(current_all_bear.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "    for ax in axs[2,:]:\n",
    "        ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "    axs[2, 0].axhline(current_all_bear[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "    axs[2, 1].axhline(current_all_bear[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "    axs[2, 2].axhline(current_all_bear[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "    axs[2, 0].set_ylabel('Bear test', fontsize=16)\n",
    "\n",
    "    axs[0, 0].set_title(\"All-trained\", fontsize=16)\n",
    "    axs[0, 1].set_title(\"Bull-trained\", fontsize=16)\n",
    "    axs[0, 2].set_title(\"Bear-trained\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        vals = ax.get_yticks()\n",
    "        print(vals)\n",
    "        ax.set_yticklabels(['+{:,.2%}'.format(abs(x)) if x > 0 else '{:,.2%}'.format(x) if x == 0 else '-{:,.2%}'.format(abs(x)) for x in vals])\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d047e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bull_bear_geom_deciles(bull_df, bear_df, all_df):\n",
    "    from scipy.stats import gmean\n",
    "    #BULL/BEAR TO BULL/BEAR RETURNS GEOM\n",
    "    plt.rcdefaults()\n",
    "    \n",
    "    current_bull = bull_df.copy()\n",
    "    current_bear = bear_df.copy()\n",
    "    current_all  = all_df.copy()\n",
    "\n",
    "    current_bull[\"trr_5_fwd\"] = (1 + current_bull[\"trr_5_fwd\"]).pow(5) - 1\n",
    "    current_bear[\"trr_5_fwd\"] = (1 + current_bear[\"trr_5_fwd\"]).pow(5) - 1\n",
    "    current_all[\"trr_5_fwd\"] = (1 + current_all[\"trr_5_fwd\"]).pow(5) - 1\n",
    "\n",
    "    current_bull[\"trr_5\"] = (1 + current_bull[\"trr_5\"]).pow(5) - 1\n",
    "    current_bear[\"trr_5\"] = (1 + current_bear[\"trr_5\"]).pow(5) - 1\n",
    "    current_all[\"trr_5\"] = (1 + current_all[\"trr_5\"]).pow(5) - 1\n",
    "\n",
    "    assert(not (na_test and global_test))\n",
    "\n",
    "    assert(not (bull_bear_period_rough and bull_bear_period))\n",
    "\n",
    "\n",
    "    if na_test:\n",
    "        current_bull = current_bull[current_bull[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_bear = current_bear[current_bear[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_all  = current_all[current_all[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "    if global_test:\n",
    "        current_bull = current_bull[~current_bull[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_bear = current_bear[~current_bear[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_all  = current_all[~current_all[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "\n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "    if bull_bear_period_rough:\n",
    "        current_bull_bull = current_bull[current_bull[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "        current_bear_bull = current_bear[current_bear[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "        current_all_bull  = current_all[current_all[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "\n",
    "        current_bull_bear = current_bull[current_bull[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "        current_bear_bear = current_bear[current_bear[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "        current_all_bear  = current_all[current_all[\"date\"] <= pd.Timestamp(\"2022-10-14\")]\n",
    "\n",
    "        print(current_all_bull[\"date\"].max())\n",
    "        print(current_all_bull[\"date\"].min())\n",
    "\n",
    "        print(current_all_bear[\"date\"].max())\n",
    "        print(current_all_bear[\"date\"].min())\n",
    "\n",
    "\n",
    "    if bull_bear_period:\n",
    "        current_bull_bull = choose_bull_data(current_bull)\n",
    "        current_bear_bull = choose_bull_data(current_bear)\n",
    "        current_all_bull  = choose_bull_data(current_all)\n",
    "\n",
    "        current_bull_bear = choose_bear_data(current_bull)\n",
    "        current_bear_bear = choose_bear_data(current_bear)\n",
    "        current_all_bear  = choose_bear_data(current_all)\n",
    "\n",
    "        print(current_all_bull[\"date\"].max())\n",
    "        print(current_all_bull[\"date\"].min())\n",
    "\n",
    "        print(current_all_bear[\"date\"].max())\n",
    "        print(current_all_bear[\"date\"].min())\n",
    "\n",
    "\n",
    "    current_bull_bull = add_quantiles(current_bull_bull)\n",
    "    current_bear_bull = add_quantiles(current_bear_bull)\n",
    "    current_all_bull = add_quantiles(current_all_bull)\n",
    "\n",
    "    current_bull_bear = add_quantiles(current_bull_bear)\n",
    "    current_bear_bear = add_quantiles(current_bear_bear)\n",
    "    current_all_bear = add_quantiles(current_all_bear)\n",
    "\n",
    "    current_bull = add_quantiles(current_bull)\n",
    "    current_bear = add_quantiles(current_bear)\n",
    "    current_all = add_quantiles(current_all)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "    gmean_quantiles_all = ((current_all.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_all.plot(kind=\"bar\", grid=True, ax=axs[0,0])\n",
    "\n",
    "    gmean_quantiles_bull = ((current_bull.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_bull.plot(kind=\"bar\", grid=True, ax=axs[0,1])\n",
    "\n",
    "    gmean_quantiles_bear = ((current_bear.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_bear.plot(kind=\"bar\", grid=True, ax=axs[0,2])\n",
    "\n",
    "    max_y = max(max(gmean_quantiles_all),\n",
    "               max(gmean_quantiles_bull),\n",
    "               max(gmean_quantiles_bear))\n",
    "\n",
    "    min_y = min(min(gmean_quantiles_all),\n",
    "               min(gmean_quantiles_bull),\n",
    "               min(gmean_quantiles_bear))\n",
    "    for ax in axs[0,:]:\n",
    "        ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "\n",
    "    axs[0, 0].axhline(gmean(current_all.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[0, 1].axhline(gmean(current_all.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[0, 2].axhline(gmean(current_all.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "\n",
    "    axs[0, 0].set_ylabel('All test', fontsize=16)\n",
    "\n",
    "    gmean_quantiles_all_bull = ((current_all_bull.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_all_bull.plot(kind=\"bar\", grid=True, ax=axs[1,0])\n",
    "\n",
    "    gmean_quantiles_bull_bull = ((current_bull_bull.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_bull_bull.plot(kind=\"bar\", grid=True, ax=axs[1,1])\n",
    "\n",
    "    gmean_quantiles_bear_bull = ((current_bear_bull.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_bear_bull.plot(kind=\"bar\", grid=True, ax=axs[1,2])\n",
    "\n",
    "    max_y = max(max(gmean_quantiles_all_bull),\n",
    "               max(gmean_quantiles_bull_bull),\n",
    "               max(gmean_quantiles_bear_bull))\n",
    "\n",
    "    min_y = min(min(gmean_quantiles_all_bull),\n",
    "               min(gmean_quantiles_bull_bull),\n",
    "               min(gmean_quantiles_bear_bull))\n",
    "    for ax in axs[1,:]:\n",
    "        ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "    axs[1, 0].axhline(gmean(current_all_bull.groupby(\"date\")[target_variable + \"_fwd\"].mean() + 1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[1, 1].axhline(gmean(current_all_bull.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[1, 2].axhline(gmean(current_all_bull.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[1, 0].set_ylabel('Bull test', fontsize=16)\n",
    "\n",
    "\n",
    "    gmean_quantiles_all_bear = ((current_all_bear.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_all_bear.plot(kind=\"bar\", grid=True, ax=axs[2,0]) \n",
    "\n",
    "    gmean_quantiles_bull_bear = ((current_bull_bear.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_bull_bear.plot(kind=\"bar\", grid=True, ax=axs[2,1])\n",
    "\n",
    "    gmean_quantiles_bear_bear = ((current_bear_bear.groupby([\"date\",\"conviction_quantile\"])[target_variable + \"_fwd\"].mean() + 1).groupby(\"conviction_quantile\").apply(gmean) - 1)\n",
    "    gmean_quantiles_bear_bear.plot(kind=\"bar\", grid=True, ax=axs[2,2])\n",
    "\n",
    "    max_y = max(max(gmean_quantiles_all_bear),\n",
    "               max(gmean_quantiles_bull_bear),\n",
    "               max(gmean_quantiles_bear_bear))\n",
    "\n",
    "    min_y = min(min(gmean_quantiles_all_bear),\n",
    "               min(gmean_quantiles_bull_bear),\n",
    "               min(gmean_quantiles_bear_bear))\n",
    "    for ax in axs[2,:]:\n",
    "        ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "    axs[2, 0].axhline(gmean(current_all_bear.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[2, 1].axhline(gmean(current_all_bear.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "    axs[2, 2].axhline(gmean(current_all_bear.groupby(\"date\")[target_variable + \"_fwd\"].mean() +1) - 1, label=\"avg trr_5_fwd\")\n",
    "\n",
    "    axs[2, 0].set_ylabel('Bear test', fontsize=16)\n",
    "\n",
    "    axs[0, 0].set_title(\"All-trained\", fontsize=16)\n",
    "    axs[0, 1].set_title(\"Bull-trained\", fontsize=16)\n",
    "    axs[0, 2].set_title(\"Bear-trained\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        vals = ax.get_yticks()\n",
    "        ax.set_yticklabels(['+{:,.2%}'.format(abs(x)) if x > 0 else '{:,.2%}'.format(x) if x == 0 else '-{:,.2%}'.format(abs(x)) for x in vals])\n",
    "\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0abf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(df_bull, df_bear, df_all, both_adaptive = False, return_min = None, return_max = None, trade_index = False):\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    import matplotlib.dates as mdates\n",
    "\n",
    "    current_bull = df_bull.copy()\n",
    "    current_bear = df_bear.copy()\n",
    "    current_all = df_all.copy()\n",
    "\n",
    "    current_bull[\"date\"] = pd.to_datetime(current_bull[\"date\"])\n",
    "    current_bear[\"date\"] = pd.to_datetime(current_bear[\"date\"])\n",
    "    current_all[\"date\"] = pd.to_datetime(current_all[\"date\"])\n",
    "\n",
    "\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "\n",
    "    days_offset = 7 #Because trr_5_fwd is 7 days in the future, shift dates forward 7 days\n",
    "\n",
    "    assert(not (na_test and global_test))\n",
    "\n",
    "\n",
    "    if na_test:\n",
    "        current_bull = current_bull[current_bull[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_bear = current_bear[current_bear[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_all  = current_all[current_all[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        print(\"na_test\")\n",
    "\n",
    "    if global_test:\n",
    "        current_bull = current_bull[~current_bull[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_bear = current_bear[~current_bear[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        current_all  = current_all[~current_all[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "        print(\"global_test\")\n",
    "\n",
    "\n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "    current_bull = add_quantiles(current_bull)\n",
    "    current_bear = add_quantiles(current_bear)\n",
    "    current_all = add_quantiles(current_all)\n",
    "\n",
    "    current_bull[\"trr_5_fwd_tot\"] = (1 + current_bull[\"trr_5_fwd\"]).pow(5) - 1\n",
    "    current_bear[\"trr_5_fwd_tot\"] = (1 + current_bear[\"trr_5_fwd\"]).pow(5) - 1\n",
    "    current_all[\"trr_5_fwd_tot\"] = (1 + current_all[\"trr_5_fwd\"]).pow(5) - 1\n",
    "\n",
    "    if return_min is not None:\n",
    "        current_bull = current_bull[current_bull[\"trr_5_fwd_tot\"] >= return_min]\n",
    "        current_bear = current_bear[current_bear[\"trr_5_fwd_tot\"] >= return_min]\n",
    "        current_all = current_all[current_all[\"trr_5_fwd_tot\"] >= return_min]\n",
    "\n",
    "    if return_max is not None:\n",
    "        current_bull = current_bull[current_bull[\"trr_5_fwd_tot\"] <= return_max]\n",
    "        current_bear = current_bear[current_bear[\"trr_5_fwd_tot\"] <= return_max]\n",
    "        current_all = current_all[current_all[\"trr_5_fwd_tot\"] <= return_max]\n",
    "\n",
    "\n",
    "    current_all_returns = (current_all[current_all[\"conviction_quantile\"].isin(buy_deciles)].groupby(\"date\")[\"trr_5_fwd_tot\"].mean() -\\\n",
    "        current_all[current_all[\"conviction_quantile\"].isin(sell_deciles)].groupby(\"date\")[\"trr_5_fwd_tot\"].mean()).reset_index()\n",
    "\n",
    "    current_bear_returns = (current_bear[current_bear[\"conviction_quantile\"].isin(buy_deciles)].groupby(\"date\")[\"trr_5_fwd_tot\"].mean() -\\\n",
    "        current_bear[current_bear[\"conviction_quantile\"].isin(sell_deciles)].groupby(\"date\")[\"trr_5_fwd_tot\"].mean()).reset_index()\n",
    "\n",
    "    current_bull_returns = (current_bull[current_bull[\"conviction_quantile\"].isin(buy_deciles)].groupby(\"date\")[\"trr_5_fwd_tot\"].mean() -\\\n",
    "        current_bull[current_bull[\"conviction_quantile\"].isin(sell_deciles)].groupby(\"date\")[\"trr_5_fwd_tot\"].mean()).reset_index()\n",
    "\n",
    "    current_index = current_all.copy()\n",
    "\n",
    "    current_index_returns = current_index.groupby(\"date\")[\"trr_5_fwd_tot\"].mean().reset_index()\n",
    "\n",
    "    current_all_returns[\"trr_5_fwd_tot\"] = current_all_returns[\"trr_5_fwd_tot\"] - costs\n",
    "    current_bear_returns[\"trr_5_fwd_tot\"] = current_bear_returns[\"trr_5_fwd_tot\"] - costs\n",
    "    current_bull_returns[\"trr_5_fwd_tot\"] = current_bull_returns[\"trr_5_fwd_tot\"] - costs\n",
    "\n",
    "    current_all_returns[\"date\"] = current_all_returns[\"date\"] + pd.Timedelta(days=days_offset)\n",
    "    current_bear_returns[\"date\"] = current_bear_returns[\"date\"] + pd.Timedelta(days=days_offset)\n",
    "    current_bull_returns[\"date\"] = current_bull_returns[\"date\"] + pd.Timedelta(days=days_offset)\n",
    "    current_index_returns[\"date\"] = current_index_returns[\"date\"] + pd.Timedelta(days=days_offset)\n",
    "\n",
    "    current_all_returns = current_all_returns.append({\"trr_5_fwd_tot\": 0, \"date\": current_all_returns[\"date\"].min() - pd.Timedelta(days=7)}, ignore_index=True).sort_values(\"date\")\n",
    "    current_bear_returns = current_bear_returns.append({\"trr_5_fwd_tot\": 0, \"date\": current_bear_returns[\"date\"].min() - pd.Timedelta(days=7)}, ignore_index=True).sort_values(\"date\")\n",
    "    current_bull_returns = current_bull_returns.append({\"trr_5_fwd_tot\": 0, \"date\": current_bull_returns[\"date\"].min() - pd.Timedelta(days=7)}, ignore_index=True).sort_values(\"date\")\n",
    "    current_index_returns = current_index_returns.append({\"trr_5_fwd_tot\": 0, \"date\": current_index_returns[\"date\"].min() - pd.Timedelta(days=7)}, ignore_index=True).sort_values(\"date\")\n",
    "\n",
    "    current_bull[\"date\"] = current_bull[\"date\"].dt.date\n",
    "    current_bear[\"date\"] = current_bear[\"date\"].dt.date\n",
    "    current_all[\"date\"] = current_all[\"date\"].dt.date\n",
    "    current_index_returns[\"date\"] = current_index_returns[\"date\"].dt.date\n",
    "\n",
    "\n",
    "    ((current_index_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                label=\"Index\",\n",
    "                                                                                color=\"black\",\n",
    "                                                                                linestyle='--',\n",
    "                                                                                ax=ax)\n",
    "    if trade_index:\n",
    "        current_trade_index_returns = choose_bear_data(current_index_returns)\n",
    "        current_trade_index_returns[\"trr_5_fwd_tot\"] = - current_trade_index_returns[\"trr_5_fwd_tot\"]\n",
    "\n",
    "        current_trade_index_returns = pd.concat([current_trade_index_returns, choose_bull_data(current_index_returns, 0), choose_non_bull_bear_data(current_index_returns, 0)]).sort_values(\"date\")\n",
    "\n",
    "\n",
    "        ((current_trade_index_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                    label=\"Index, adaptive\",\n",
    "                                                                                    color=\"black\",\n",
    "                                                                                    ax=ax)\n",
    "    ((current_all_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                label=\"All-trained\",\n",
    "                                                                                color=\"tab:green\",\n",
    "                                                                                ax=ax)\n",
    "    ((current_bear_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                label=\"Bear-trained\",\n",
    "                                                                                color=\"tab:red\",\n",
    "                                                                                ax=ax)\n",
    "    ((current_bull_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                label=\"Bull-trained\", \n",
    "                                                                                color=\"tab:blue\",\n",
    "                                                                                ax=ax)\n",
    "    if both_adaptive:\n",
    "        current_adaptive_rough_returns = pd.concat([current_bull_returns[current_bull_returns[\"date\"] > (pd.Timestamp(\"2022-10-14\") + pd.Timedelta(days=adaptive_latency_days))], \n",
    "                                               current_bear_returns[current_bear_returns[\"date\"] <= (pd.Timestamp(\"2022-10-14\") + pd.Timedelta(days=adaptive_latency_days))]]).reset_index().sort_values(\"date\")\n",
    "\n",
    "        current_adaptive_returns = pd.concat([choose_bull_data(current_bull_returns, 0), choose_bear_data(current_bear_returns, 0), choose_non_bull_bear_data(current_all_returns, 0)]).sort_values(\"date\")\n",
    "                \n",
    "        current_adaptive_rough_returns[\"date\"] = pd.to_datetime(current_adaptive_rough_returns[\"date\"]).dt.date\n",
    "        current_adaptive_returns[\"date\"] = pd.to_datetime(current_adaptive_returns[\"date\"]).dt.date\n",
    "        \n",
    "        ((current_adaptive_rough_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                label=\"Adaptive, rough\",\n",
    "                                                                                color=\"tab:purple\",\n",
    "                                                                                ax=ax)\n",
    "        \n",
    "        ((current_adaptive_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                label=\"Adaptive\",\n",
    "                                                                                color=\"tab:pink\",\n",
    "                                                                                ax=ax)\n",
    "        \n",
    "    else:\n",
    "        if rough_adaptive_model_choice:\n",
    "            current_adaptive_returns = pd.concat([current_bull_returns.reset_index()[current_bull_returns.reset_index()[\"date\"] > (pd.Timestamp(\"2022-10-14\") + pd.Timedelta(days=adaptive_latency_days))], \n",
    "                                                   current_bear_returns.reset_index()[current_bear_returns.reset_index()[\"date\"] <= (pd.Timestamp(\"2022-10-14\") + pd.Timedelta(days=adaptive_latency_days))]]).sort_values(\"date\")\n",
    "        else:\n",
    "            current_adaptive_returns = pd.concat([choose_bull_data(current_bull_returns.reset_index(), days_offset), choose_bear_data(current_bear_returns.reset_index(), 0), choose_non_bull_bear_data(current_all_returns.reset_index(), 0)]).sort_values(\"date\")\n",
    "        \n",
    "        current_adaptive_returns[\"date\"] = pd.to_datetime(current_adaptive_returns[\"date\"]).dt.date\n",
    "\n",
    "        ((current_adaptive_returns.groupby(\"date\")[\"trr_5_fwd_tot\"].mean() + 1).cumprod() - 1).plot(figsize=(20, 10), \n",
    "                                                                                    label=\"Adaptive\",\n",
    "                                                                                    color=\"tab:purple\",\n",
    "                                                                                    ax=ax)\n",
    "        \n",
    "\n",
    "\n",
    "    ax.lines[0].set_linewidth(3)\n",
    "    ax.lines[1].set_linewidth(3)\n",
    "    ax.lines[2].set_linewidth(3)\n",
    "    ax.lines[3].set_linewidth(3)\n",
    "    ax.lines[4].set_linewidth(3)\n",
    "    \n",
    "    if both_adaptive:\n",
    "        ax.lines[5].set_linewidth(3)\n",
    "        if trade_index:\n",
    "            ax.lines[6].set_linewidth(3)\n",
    "    elif trade_index:\n",
    "        ax.lines[5].set_linewidth(3)\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.axvline(x=(pd.Timestamp('2022-10-14')), color=\"grey\", linestyle=\"--\", linewidth=3, label=\"Last bear friday\")\n",
    "\n",
    "\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter((mdates.DateFormatter('%b\\n%Y')))\n",
    "    ax.xaxis.set_minor_formatter((mdates.DateFormatter('%b')))\n",
    "    \n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "\n",
    "    plt.grid(True, which=\"both\", axis=\"both\")\n",
    "\n",
    "    ax.set_xlim(pd.Timestamp('2022-01-07'), pd.Timestamp('2023-08-30'))\n",
    "\n",
    "    plt.legend(fontsize=16)\n",
    "    \n",
    "    ax.set_xlabel(\"\")\n",
    "    vals = ax.get_yticks()\n",
    "    ax.set_yticklabels(['+{:,.2%}'.format(abs(x)) if x > 0 else '{:,.2%}'.format(x) if x == 0 else '-{:,.2%}'.format(abs(x)) for x in vals])\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde69947",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_market_cap_percentile_na = 0.6\n",
    "min_market_cap_percentile_global = 0.65\n",
    "volume_usd_5_min = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a16a1",
   "metadata": {},
   "source": [
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67a475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_na = pd.read_parquet(\"catboost_na_2023-11-22-05-46-21_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_na = remove_small_caps(results_na)\n",
    "results_na = set_time_period(results_na, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea83928",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g = pd.read_parquet(\"catboost_g_2023-11-23-14-30-07_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_g = remove_small_caps(results_g)\n",
    "results_g = set_time_period(results_g, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b75773",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna = pd.read_parquet(\"catboost_gna_2023-11-23-11-55-52_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_gna = remove_small_caps(results_gna)\n",
    "results_gna = set_time_period(results_gna, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_detached = pd.read_parquet(\"catboost_NA_2023-12-08-18-39-20_detached_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_na_detached = remove_small_caps(results_na_detached)\n",
    "results_na_detached = set_time_period(results_na_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b9fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_gna_detached = pd.read_parquet(\"catboost_Global_2023-12-08-20-20-26_detached_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_gna_detached = remove_small_caps(results_gna_detached)\n",
    "results_gna_detached = set_time_period(results_gna_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_detached = pd.read_parquet(\"catboost_ROW_2023-12-08-20-11-01_detached_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_g_detached = remove_small_caps(results_g_detached)\n",
    "results_g_detached = set_time_period(results_g_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_bear = pd.read_parquet(\"catboost_NA_2023-12-08-19-01-28_detached_bear_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_na_bear = remove_small_caps(results_na_bear)\n",
    "results_na_bear = set_time_period(results_na_bear, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fffed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_bear = pd.read_parquet(\"catboost_Global_2023-12-08-19-24-25_detached_bear_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_gna_bear = remove_small_caps(results_gna_bear)\n",
    "results_gna_bear = set_time_period(results_gna_bear, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_bear = pd.read_parquet(\"catboost_ROW_2023-12-08-19-28-31_detached_bear_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_g_bear = remove_small_caps(results_g_bear)\n",
    "results_g_bear = set_time_period(results_g_bear, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_bull = pd.read_parquet(\"catboost_NA_2023-12-08-19-03-49_detached_bull_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_na_bull = remove_small_caps(results_na_bull)\n",
    "results_na_bull = set_time_period(results_na_bull, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_bull = pd.read_parquet(\"catboost_Global_2023-12-08-19-17-12_detached_bull_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_gna_bull = remove_small_caps(results_gna_bull)\n",
    "results_gna_bull = set_time_period(results_gna_bull, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c713a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_bull = pd.read_parquet(\"catboost_ROW_2023-12-08-19-08-29_detached_bull_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_g_bull = remove_small_caps(results_g_bull)\n",
    "results_g_bull = set_time_period(results_g_bull, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ff3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGION TO REGION\n",
    "plt.rcdefaults()\n",
    "current_global = results_gna_detached.copy()\n",
    "current_na = results_na_detached.copy()\n",
    "current_row  = results_g_detached.copy()\n",
    "title = \"Regions Catboost\"\n",
    "\n",
    "bull_period_rough = False\n",
    "bear_period_rough = False\n",
    "bull_period = False\n",
    "bear_period = False\n",
    "\n",
    "assert(not (bull_period and bear_period))\n",
    "assert(not (bull_period_rough and bear_period_rough))\n",
    "\n",
    "current_global[\"trr_5_fwd\"] = (1 + current_global[\"trr_5_fwd\"]).pow(5) - 1\n",
    "current_na[\"trr_5_fwd\"] = (1 + current_na[\"trr_5_fwd\"]).pow(5) - 1\n",
    "current_row[\"trr_5_fwd\"] = (1 + current_row[\"trr_5_fwd\"]).pow(5) - 1\n",
    "\n",
    "\n",
    "print(current_global[\"date\"].max())\n",
    "print(current_global[\"date\"].min())\n",
    "\n",
    "if bull_period_rough:\n",
    "    current_bull = current_bull[current_bull[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "    current_bear = current_bear[current_bear[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "    current_all  = current_all[current_all[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "if bear_period_rough:\n",
    "    current_bull = current_bull[current_bull[\"date\"] < pd.Timestamp(\"2022-10-14\")]\n",
    "    current_bear = current_bear[current_bear[\"date\"] < pd.Timestamp(\"2022-10-14\")]\n",
    "    current_all  = current_all[current_all[\"date\"] < pd.Timestamp(\"2022-10-14\")]\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "    \n",
    "if bear_period:\n",
    "    current_bull = choose_bear_data(current_bull)\n",
    "    current_bear = choose_bear_data(current_bear)\n",
    "    current_all = choose_bear_data(current_all)\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "    \n",
    "if bull_period:\n",
    "    current_bull = choose_bull_data(current_bull)\n",
    "    current_bear = choose_bull_data(current_bear)\n",
    "    current_all = choose_bull_data(current_all)\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "current_global_na = current_global[current_global[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_na_na = current_na[current_na[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_row_na  = current_row[current_row[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "current_global_row = current_global[~current_global[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_na_row = current_na[~current_na[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_row_row  = current_row[~current_row[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "current_global_na = add_quantiles(current_global_na)\n",
    "current_na_na = add_quantiles(current_na_na)\n",
    "current_row_na = add_quantiles(current_row_na)\n",
    "\n",
    "current_global_row = add_quantiles(current_global_row)\n",
    "current_na_row = add_quantiles(current_na_row)\n",
    "current_row_row = add_quantiles(current_row_row)\n",
    "\n",
    "current_global = add_quantiles(current_global)\n",
    "current_na = add_quantiles(current_na)\n",
    "current_row = add_quantiles(current_row)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "current_global.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,0])\n",
    "\n",
    "current_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,1])\n",
    "\n",
    "current_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,2])\n",
    "\n",
    "max_y = max(max(current_global.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "min_y = min(min(current_global.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "for ax in axs[0,:]:\n",
    "    ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "\n",
    "axs[0, 0].axhline(current_global[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[0, 1].axhline(current_global[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[0, 2].axhline(current_global[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "axs[0, 0].set_ylabel('Global test', fontsize=16)\n",
    "\n",
    "current_global_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,0])\n",
    "current_na_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,1])\n",
    "current_row_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,2])\n",
    "\n",
    "max_y = max(max(current_global_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_na_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_row_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "min_y = min(min(current_global_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_na_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_row_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "for ax in axs[1,:]:\n",
    "    ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "axs[1, 0].axhline(current_global_na[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[1, 1].axhline(current_global_na[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[1, 2].axhline(current_global_na[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "axs[1, 0].set_ylabel('NA test', fontsize=16)\n",
    "\n",
    "\n",
    "current_global_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,0])\n",
    "current_na_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,1])\n",
    "current_row_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,2])\n",
    "\n",
    "max_y = max(max(current_global_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_na_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_row_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "min_y = min(min(current_global_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_na_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_row_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "for ax in axs[2,:]:\n",
    "    ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "axs[2, 0].axhline(current_global_row[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[2, 1].axhline(current_global_row[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[2, 2].axhline(current_global_row[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "axs[2, 0].set_ylabel('ROW test', fontsize=16)\n",
    "\n",
    "axs[0, 0].set_title(\"Global train\", fontsize=16)\n",
    "axs[0, 1].set_title(\"NA train\", fontsize=16)\n",
    "axs[0, 2].set_title(\"ROW train\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    vals = ax.get_yticks()\n",
    "    print(vals)\n",
    "    ax.set_yticklabels(['+{:,.2%}'.format(abs(x)) if x > 0 else '{:,.2%}'.format(x) if x == 0 else '-{:,.2%}'.format(abs(x)) for x in vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_test = False\n",
    "global_test = False\n",
    "\n",
    "bull_bear_period_rough = True\n",
    "bull_bear_period = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BULL/BEAR TO BULL/BEAR RETURNS\n",
    "plt.rcdefaults()\n",
    "\n",
    "current_bull = results_gna_bull.copy()\n",
    "current_bear = results_gna_bear.copy()\n",
    "current_all  = results_gna_detached.copy()\n",
    "\n",
    "assert(not (na_test and global_test))\n",
    "\n",
    "assert(not (bull_bear_period_rough and bull_bear_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_mean_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesCatboostNABearBullRough.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898413cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_geom_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesGeomCatboostNABearBullRough.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9984ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_deciles = [9]\n",
    "sell_deciles = [0]\n",
    "\n",
    "rough_adaptive_model_choice = False\n",
    "\n",
    "adaptive_latency_days = 0\n",
    "\n",
    "costs = 1 * (1/100)\n",
    "\n",
    "fig, ax = plot_cumulative_returns(current_bull, current_bear, current_all, both_adaptive=True, trade_index=True)\n",
    "\n",
    "#fig.savefig(\"../figures/CumulativeReturnsCatboostGNATop3Cost1BothAdaptive.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13624c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_cm = plot_cm(current_all, bear_test=True, rough=True)\n",
    "plt_cm.figure.savefig(f'../figures/CMCatboostGNAAllBearRough.pdf', dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22e7f9",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c865893",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_gna_detached = pd.read_parquet(\"xgboost_Global_2023-12-08-13-27-00_detached_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_gna_detached = remove_small_caps(results_xgb_gna_detached)\n",
    "results_xgb_gna_detached = set_time_period(results_xgb_gna_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_gna_bull = pd.read_parquet(\"xgboost_Global_2023-12-08-15-27-52_detached_bull_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_gna_bull = remove_small_caps(results_xgb_gna_bull)\n",
    "results_xgb_gna_bull = set_time_period(results_xgb_gna_bull, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f595fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_gna_bear = pd.read_parquet(\"xgboost_Global_2023-12-08-14-08-35_detached_bear_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_gna_bear = remove_small_caps(results_xgb_gna_bear)\n",
    "results_xgb_gna_bear = set_time_period(results_xgb_gna_bear, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_na_detached = pd.read_parquet(\"xgboost_NA_2023-12-08-18-09-30_detached_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_na_detached = remove_small_caps(results_xgb_na_detached)\n",
    "results_xgb_na_detached = set_time_period(results_xgb_na_detached, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a475e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_na_bull = pd.read_parquet(\"xgboost_NA_2023-12-08-18-34-21_detached_bull_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_na_bull = remove_small_caps(results_xgb_na_bull)\n",
    "results_xgb_na_bull = set_time_period(results_xgb_na_bull, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_na_bear = pd.read_parquet(\"xgboost_NA_2023-12-08-18-29-18_detached_bear_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_na_bear = remove_small_caps(results_xgb_na_bear)\n",
    "results_xgb_na_bear = set_time_period(results_xgb_na_bear, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_g_detached = pd.read_parquet(\"xgboost_ROW_2023-12-08-17-19-04_detached_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_g_detached = remove_small_caps(results_xgb_g_detached)\n",
    "results_xgb_g_detached = set_time_period(results_xgb_g_detached, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_g_bull = pd.read_parquet(\"xgboost_ROW_2023-12-08-17-16-38_detached_bull_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_g_bull = remove_small_caps(results_xgb_g_bull)\n",
    "results_xgb_g_bull = set_time_period(results_xgb_g_bull, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xgb_g_bear = pd.read_parquet(\"xgboost_ROW_2023-12-08-17-06-52_detached_bear_trained_no_validation_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_xgb_g_bear = remove_small_caps(results_xgb_g_bear)\n",
    "results_xgb_g_bear = set_time_period(results_xgb_g_bear, \"2022-01-01\", \"2023-08-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6df3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_test = False\n",
    "global_test = False\n",
    "bull_bear_period = False\n",
    "bull_bear_period_rough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec37060",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_bull = results_xgb_gna_bull.copy()\n",
    "current_bear = results_xgb_gna_bear.copy()\n",
    "current_all = results_xgb_gna_detached.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96449402",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_mean_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesXGBoostGNABearBullRough.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_geom_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesGeomXGBoostGNABearBullRough.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_deciles = [9]\n",
    "sell_deciles = [0]\n",
    "\n",
    "rough_adaptive_model_choice = False\n",
    "\n",
    "adaptive_latency_days = 0\n",
    "\n",
    "costs = 1 * (1/100)\n",
    "\n",
    "fig, ax = plot_cumulative_returns(current_bull, current_bear, current_all, both_adaptive=True, trade_index=True)\n",
    "\n",
    "#fig.savefig(\"../figures/CumulativeReturnsXGBoostGNATop1Cost1BothAdaptive.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dcbe57",
   "metadata": {},
   "source": [
    "## LOGREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba743bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_gna_detached = pd.read_parquet(\"logreg_Global_2023-12-08-04-50-36_detached_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_gna_detached = remove_small_caps(results_log_gna_detached)\n",
    "results_log_gna_detached = set_time_period(results_log_gna_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_gna_bull = pd.read_parquet(\"logreg_Global_2023-12-08-10-49-50_detached_bull_trained_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_gna_bull = remove_small_caps(results_log_gna_bull)\n",
    "results_log_gna_bull = set_time_period(results_log_gna_bull, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_gna_bear = pd.read_parquet(\"logreg_Global_2023-12-08-10-28-17_detached_bear_trained_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_gna_bear = remove_small_caps(results_log_gna_bear)\n",
    "results_log_gna_bear = set_time_period(results_log_gna_bear, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_na_detached = pd.read_parquet(\"logreg_NA_2023-12-08-02-53-16_detached_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_na_detached = remove_small_caps(results_log_na_detached)\n",
    "results_log_na_detached = set_time_period(results_log_na_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_na_bull = pd.read_parquet(\"logreg_NA_2023-12-08-00-58-30_detached_bull_trained_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_na_bull = remove_small_caps(results_log_na_bull)\n",
    "results_log_na_bull = set_time_period(results_log_na_bull, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_na_bear = pd.read_parquet(\"logreg_NA_2023-12-08-02-19-04_detached_bear_trained_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_na_bear = remove_small_caps(results_log_na_bear)\n",
    "results_log_na_bear = set_time_period(results_log_na_bear, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25520b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_g_detached = pd.read_parquet(\"logreg_ROW_2023-12-08-06-39-14_detached_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_g_detached = remove_small_caps(results_log_g_detached)\n",
    "results_log_g_detached = set_time_period(results_log_g_detached, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_g_bull = pd.read_parquet(\"logreg_ROW_2023-12-08-10-54-22_detached_bull_trained_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_g_bull = remove_small_caps(results_log_g_bull)\n",
    "results_log_g_bull = set_time_period(results_log_g_bull, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79deb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_g_bear = pd.read_parquet(\"logreg_ROW_2023-12-08-12-13-09_detached_bear_trained_min_vol_5_1000000_min_mcap_percentile_na_0.6_min_mcap_percentile_global_0.65/results.parquet\", engine=\"pyarrow\")\n",
    "results_log_g_bear = remove_small_caps(results_log_g_bear)\n",
    "results_log_g_bear = set_time_period(results_log_g_bear, \"2022-01-01\", \"2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b169c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_test = True\n",
    "global_test = False\n",
    "\n",
    "bull_bear_period_rough = True\n",
    "bull_bear_period = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94682fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_bull = results_log_gna_bull.copy()\n",
    "current_bear = results_log_gna_bear.copy()\n",
    "current_all = results_log_gna_detached.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f61c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_mean_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesLogregNABearBull.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf468a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_geom_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesGeomLogregNABearBullRough.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec204349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "buy_deciles = [9]\n",
    "sell_deciles = [0]\n",
    "\n",
    "rough_adaptive_model_choice = False\n",
    "\n",
    "adaptive_latency_days = 0\n",
    "\n",
    "costs = 1 * (1/100)\n",
    "\n",
    "fig, ax = plot_cumulative_returns(current_bull, current_bear, current_all, both_adaptive=True, trade_index=True)\n",
    "\n",
    "#fig.savefig(\"../figures/CumulativeReturnsLogregNATop1Cost1BothAdaptive.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8579247",
   "metadata": {},
   "source": [
    "## Ensemble Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e37834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble(df_1, df_2):\n",
    "    current_df_1 = df_1.copy()\n",
    "    current_df_2 = df_2.copy()\n",
    "    \n",
    "    current_ensemble = df_1.merge(df_2, on=[\"date\", \"gvkey\"], suffixes=[\"\", \"_right\"])\n",
    "\n",
    "    current_ensemble[\"pred_2\"] = (current_ensemble[\"pred_2\"] + current_ensemble[\"pred_2_right\"]) / 2\n",
    "    current_ensemble[\"pred_1\"] = (current_ensemble[\"pred_1\"] + current_ensemble[\"pred_1_right\"]) / 2\n",
    "    current_ensemble[\"pred_0\"] = (current_ensemble[\"pred_0\"] + current_ensemble[\"pred_0_right\"]) / 2\n",
    "    current_ensemble[\"conviction\"] = (current_ensemble[\"conviction\"] + current_ensemble[\"conviction_right\"]) / 2\n",
    "\n",
    "    keep_cols = current_ensemble.columns[current_ensemble.columns.str[-6:] != \"_right\"]\n",
    "    current_ensemble = current_ensemble[keep_cols.tolist()]\n",
    "\n",
    "    #current_ensemble = add_quantiles(current_ensemble)\n",
    "    \n",
    "    return current_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b15837",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_detached_ensemble_boosting = create_ensemble(results_gna_detached, results_xgb_gna_detached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_bull_ensemble_boosting = create_ensemble(results_gna_bull, results_xgb_gna_bull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd01a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_bear_ensemble_boosting = create_ensemble(results_gna_bear, results_xgb_gna_bear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ea62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_detached_ensemble_boosting = create_ensemble(results_na_detached, results_xgb_na_detached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631176bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_bull_ensemble_boosting = create_ensemble(results_na_bull, results_xgb_na_bull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_bear_ensemble_boosting = create_ensemble(results_na_bear, results_xgb_na_bear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_detached_ensemble_boosting = create_ensemble(results_g_detached, results_xgb_g_detached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_bull_ensemble_boosting = create_ensemble(results_g_bull, results_xgb_g_bull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_bear_ensemble_boosting = create_ensemble(results_g_bear, results_xgb_g_bear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3555c",
   "metadata": {},
   "source": [
    "## Ensemble boosting + log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_detached_ensemble = create_ensemble(results_gna_detached_ensemble_boosting, results_log_gna_detached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_bull_ensemble = create_ensemble(results_gna_bull_ensemble_boosting, results_log_gna_bull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gna_bear_ensemble = create_ensemble(results_gna_bear_ensemble_boosting, results_log_gna_bear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f81c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_detached_ensemble = create_ensemble(results_na_detached_ensemble_boosting, results_log_na_detached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13798538",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_bull_ensemble = create_ensemble(results_na_bull_ensemble_boosting, results_log_na_bull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_na_bear_ensemble = create_ensemble(results_na_bear_ensemble_boosting, results_log_na_bear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_detached_ensemble = create_ensemble(results_g_detached_ensemble_boosting, results_log_g_detached)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_bull_ensemble = create_ensemble(results_g_bull_ensemble_boosting, results_log_g_bull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0270ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_g_bear_ensemble = create_ensemble(results_g_bear_ensemble_boosting, results_g_bear_ensemble_boosting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_test = True\n",
    "global_test = False\n",
    "bull_bear_period = True\n",
    "bull_bear_period_rough = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023baefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BULL/BEAR TO BULL/BEAR\n",
    "plt.rcdefaults()\n",
    "current_bull = results_na_bull_ensemble.copy()\n",
    "current_bear = results_na_bear_ensemble.copy()\n",
    "current_all  = results_na_detached_ensemble.copy()\n",
    "\n",
    "assert(not (na_test and global_test))\n",
    "\n",
    "assert(not (bull_bear_period_rough and bull_bear_period))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_mean_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesEnsembleNABearBull.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_bull_bear_geom_deciles(current_bull, current_bear, current_all)\n",
    "\n",
    "#fig.savefig(\"../figures/QuantilesGeomEnsembleNABearBull.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_deciles = [9]\n",
    "sell_deciles = [0]\n",
    "\n",
    "rough_adaptive_model_choice = False\n",
    "\n",
    "adaptive_latency_days = 0\n",
    "\n",
    "costs = 1 * (1/100)\n",
    "\n",
    "fig, ax = plot_cumulative_returns(current_bull, current_bear, current_all, both_adaptive=True, trade_index=True)\n",
    "\n",
    "#fig.savefig(\"../figures/CumulativeReturnsEnsembleNATop1Cost1BothAdaptive.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGION TO REGION\n",
    "plt.rcdefaults()\n",
    "current_global = results_gna_detached.copy()\n",
    "current_na = results_na_detached.copy()\n",
    "current_row  = results_g_detached.copy()\n",
    "title = \"Regions Catboost\"\n",
    "\n",
    "bull_period_rough = False\n",
    "bear_period_rough = False\n",
    "bull_period = False\n",
    "bear_period = False\n",
    "\n",
    "assert(not (bull_period and bear_period))\n",
    "assert(not (bull_period_rough and bear_period_rough))\n",
    "\n",
    "current_global[\"trr_5_fwd\"] = (1 + current_global[\"trr_5_fwd\"]).pow(5) - 1\n",
    "current_na[\"trr_5_fwd\"] = (1 + current_na[\"trr_5_fwd\"]).pow(5) - 1\n",
    "current_row[\"trr_5_fwd\"] = (1 + current_row[\"trr_5_fwd\"]).pow(5) - 1\n",
    "\n",
    "\n",
    "print(current_global[\"date\"].max())\n",
    "print(current_global[\"date\"].min())\n",
    "\n",
    "if bull_period_rough:\n",
    "    current_bull = current_bull[current_bull[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "    current_bear = current_bear[current_bear[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "    current_all  = current_all[current_all[\"date\"] > pd.Timestamp(\"2022-10-14\")]\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "if bear_period_rough:\n",
    "    current_bull = current_bull[current_bull[\"date\"] < pd.Timestamp(\"2022-10-14\")]\n",
    "    current_bear = current_bear[current_bear[\"date\"] < pd.Timestamp(\"2022-10-14\")]\n",
    "    current_all  = current_all[current_all[\"date\"] < pd.Timestamp(\"2022-10-14\")]\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "    \n",
    "if bear_period:\n",
    "    current_bull = choose_bear_data(current_bull)\n",
    "    current_bear = choose_bear_data(current_bear)\n",
    "    current_all = choose_bear_data(current_all)\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "    \n",
    "if bull_period:\n",
    "    current_bull = choose_bull_data(current_bull)\n",
    "    current_bear = choose_bull_data(current_bear)\n",
    "    current_all = choose_bull_data(current_all)\n",
    "    \n",
    "    print(current_all[\"date\"].max())\n",
    "    print(current_all[\"date\"].min())\n",
    "\n",
    "current_global_na = current_global[current_global[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_na_na = current_na[current_na[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_row_na  = current_row[current_row[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "current_global_row = current_global[~current_global[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_na_row = current_na[~current_na[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "current_row_row  = current_row[~current_row[\"currency\"].isin([\"USD\", \"CAD\"])]\n",
    "\n",
    "current_global_na = add_quantiles(current_global_na)\n",
    "current_na_na = add_quantiles(current_na_na)\n",
    "current_row_na = add_quantiles(current_row_na)\n",
    "\n",
    "current_global_row = add_quantiles(current_global_row)\n",
    "current_na_row = add_quantiles(current_na_row)\n",
    "current_row_row = add_quantiles(current_row_row)\n",
    "\n",
    "current_global = add_quantiles(current_global)\n",
    "current_na = add_quantiles(current_na)\n",
    "current_row = add_quantiles(current_row)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "current_global.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,0])\n",
    "\n",
    "current_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,1])\n",
    "\n",
    "current_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[0,2])\n",
    "\n",
    "max_y = max(max(current_global.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "min_y = min(min(current_global.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "for ax in axs[0,:]:\n",
    "    ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "\n",
    "axs[0, 0].axhline(current_global[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[0, 1].axhline(current_global[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[0, 2].axhline(current_global[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "axs[0, 0].set_ylabel('Global test', fontsize=16)\n",
    "\n",
    "current_global_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,0])\n",
    "current_na_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,1])\n",
    "current_row_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[1,2])\n",
    "\n",
    "max_y = max(max(current_global_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_na_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_row_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "min_y = min(min(current_global_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_na_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_row_na.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "for ax in axs[1,:]:\n",
    "    ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "axs[1, 0].axhline(current_global_na[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[1, 1].axhline(current_global_na[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[1, 2].axhline(current_global_na[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "axs[1, 0].set_ylabel('NA test', fontsize=16)\n",
    "\n",
    "\n",
    "current_global_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,0])\n",
    "current_na_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,1])\n",
    "current_row_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean().plot(kind=\"bar\", grid=True, ax=axs[2,2])\n",
    "\n",
    "max_y = max(max(current_global_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_na_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           max(current_row_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "\n",
    "min_y = min(min(current_global_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_na_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()),\n",
    "           min(current_row_row.groupby(\"conviction_quantile\")[target_variable + \"_fwd\"].mean()))\n",
    "for ax in axs[2,:]:\n",
    "    ax.set_ylim(min_y - 0.001, max_y + 0.001)\n",
    "\n",
    "axs[2, 0].axhline(current_global_row[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[2, 1].axhline(current_global_row[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "axs[2, 2].axhline(current_global_row[target_variable + \"_fwd\"].mean(), label=\"avg trr_5_fwd\")\n",
    "\n",
    "axs[2, 0].set_ylabel('ROW test', fontsize=16)\n",
    "\n",
    "axs[0, 0].set_title(\"Global train\", fontsize=16)\n",
    "axs[0, 1].set_title(\"NA train\", fontsize=16)\n",
    "axs[0, 2].set_title(\"ROW train\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    vals = ax.get_yticks()\n",
    "    print(vals)\n",
    "    ax.set_yticklabels(['+{:,.2%}'.format(abs(x)) if x > 0 else '{:,.2%}'.format(x) if x == 0 else '-{:,.2%}'.format(abs(x)) for x in vals])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
